{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COEN 140: Homework 2, LDA & QDA\n",
    "\n",
    "## Robbie Culkn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     0    1    2    3            4\n",
      "0  5.1  3.5  1.4  0.2  Iris-setosa\n",
      "1  4.9  3.0  1.4  0.2  Iris-setosa\n",
      "2  4.7  3.2  1.3  0.2  Iris-setosa\n",
      "3  4.6  3.1  1.5  0.2  Iris-setosa\n",
      "4  5.0  3.6  1.4  0.2  Iris-setosa\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Iris-setosa        50\n",
       "Iris-versicolor    50\n",
       "Iris-virginica     50\n",
       "Name: 4, dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table = pd.read_csv('data/iris.csv',header=None)\n",
    "print table.head()\n",
    "table[4].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train - Test split\n",
    "#### 1. Break the sample into 80% for training, and 20% for test datasets. You can choose the first 80% instances from each class for training and the rest for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(120, 5)\n",
      "(30, 5)\n"
     ]
    }
   ],
   "source": [
    "train = table[0:40].append(table[50:90]).append(table[100:140])\n",
    "test  = table[40:50].append(table[90:100]).append(table[140:150])\n",
    "print train.shape\n",
    "print test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "setosa =     train[train[4] == 'Iris-setosa']\n",
    "versicolor = train[train[4] == 'Iris-versicolor']\n",
    "virginica =  train[train[4] == 'Iris-virginica']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "setosa\n",
      "     0    1    2    3            4\n",
      "0  5.1  3.5  1.4  0.2  Iris-setosa\n",
      "1  4.9  3.0  1.4  0.2  Iris-setosa\n",
      "2  4.7  3.2  1.3  0.2  Iris-setosa\n",
      "3  4.6  3.1  1.5  0.2  Iris-setosa\n",
      "4  5.0  3.6  1.4  0.2  Iris-setosa\n",
      "\n",
      "versicolor\n",
      "      0    1    2    3                4\n",
      "50  7.0  3.2  4.7  1.4  Iris-versicolor\n",
      "51  6.4  3.2  4.5  1.5  Iris-versicolor\n",
      "52  6.9  3.1  4.9  1.5  Iris-versicolor\n",
      "53  5.5  2.3  4.0  1.3  Iris-versicolor\n",
      "54  6.5  2.8  4.6  1.5  Iris-versicolor\n",
      "\n",
      "virginica\n",
      "       0    1    2    3               4\n",
      "100  6.3  3.3  6.0  2.5  Iris-virginica\n",
      "101  5.8  2.7  5.1  1.9  Iris-virginica\n",
      "102  7.1  3.0  5.9  2.1  Iris-virginica\n",
      "103  6.3  2.9  5.6  1.8  Iris-virginica\n",
      "104  6.5  3.0  5.8  2.2  Iris-virginica\n"
     ]
    }
   ],
   "source": [
    "print 'setosa'\n",
    "print setosa.head()\n",
    "print '\\nversicolor'\n",
    "print versicolor.head()\n",
    "print '\\nvirginica'\n",
    "print virginica.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#drop labels\n",
    "trn_setosa = setosa.drop(4,axis=1)\n",
    "trn_versicolor = versicolor.drop(4,axis=1)\n",
    "trn_virginica = virginica.drop(4,axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Probability Density Function\n",
    "see eqn 11.1 at this link: http://www.hep.caltech.edu/~NarskyPorter/Excerpts/Pages221_227.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def P(x,mean,cov):\n",
    "    n_features = x.shape[0]\n",
    "\n",
    "    first = 1/math.sqrt(((2.0*math.pi)**n_features) * np.linalg.det(cov)) \n",
    "    second =  math.exp(-0.5*np.dot(np.dot((x-mean),np.linalg.inv(cov)),(x-mean)[np.newaxis].T) )\n",
    "    \n",
    "    return first*second"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training: Compute sample mean & sample covariance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def my_mean(X):\n",
    "    means = []\n",
    "    for col in X.values.T:\n",
    "        means.append(col.sum()/float(X.shape[0]))\n",
    "    return np.array(means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def my_cov(X):\n",
    "    total_cov = np.zeros((X.shape[1],X.shape[1]))\n",
    "    mean = my_mean(X)\n",
    "    for row in range(X.shape[0]):\n",
    "        total_cov += np.outer((X.iloc[row].values - mean),(X.iloc[row].values - mean))\n",
    "    cov = total_cov/float(X.shape[0]-1) #n-1 in order to be an unbiased estimator\n",
    "    return cov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'setosa': array([ 5.0375,  3.44  ,  1.4625,  0.2325]), 'versicolor': array([ 6.01  ,  2.78  ,  4.3175,  1.35  ]), 'virginica': array([ 6.6225,  2.96  ,  5.6075,  1.99  ])}\n",
      "{'setosa': array([[ 0.13112179,  0.09897436,  0.01298077,  0.01362179],\n",
      "       [ 0.09897436,  0.13271795,  0.00205128,  0.0145641 ],\n",
      "       [ 0.01298077,  0.00205128,  0.02958333,  0.00458333],\n",
      "       [ 0.01362179,  0.0145641 ,  0.00458333,  0.00994231]]), 'versicolor': array([[ 0.27374359,  0.08661538,  0.17212821,  0.05230769],\n",
      "       [ 0.08661538,  0.11087179,  0.08087179,  0.04538462],\n",
      "       [ 0.17212821,  0.08087179,  0.20353205,  0.07371795],\n",
      "       [ 0.05230769,  0.04538462,  0.07371795,  0.04307692]]), 'virginica': array([[ 0.46794231,  0.11041026,  0.35777564,  0.05125641],\n",
      "       [ 0.11041026,  0.11323077,  0.08107692,  0.04625641],\n",
      "       [ 0.35777564,  0.08107692,  0.34532692,  0.05930769],\n",
      "       [ 0.05125641,  0.04625641,  0.05930769,  0.07425641]])}\n"
     ]
    }
   ],
   "source": [
    "means = {}\n",
    "means['setosa']  = my_mean(trn_setosa)\n",
    "means['versicolor'] = my_mean(trn_versicolor)\n",
    "means['virginica'] = my_mean(trn_virginica)\n",
    "\n",
    "covs = {}\n",
    "covs['setosa'] = my_cov(trn_setosa)\n",
    "covs['versicolor'] = my_cov(trn_versicolor)\n",
    "covs['virginica'] = my_cov(trn_virginica)\n",
    "\n",
    "cov_avg = (covs['setosa'] + covs['versicolor'] + covs['virginica'])/3.0\n",
    "\n",
    "print means\n",
    "print covs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Discriminant Analysis\n",
    "#### 2. Build an LDA classifier based on the training data. Report the training and test errors for your classifier. \n",
    "note: using avg of 3 cov matricies as this was taught in class, but should be using a pooled cov matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def LDA(x, mu, avg_cov):\n",
    "    prob = {}\n",
    "    prob['Iris-setosa'] = P(x,mu['setosa'],avg_cov)\n",
    "    prob['Iris-versicolor'] = P(x,mu['versicolor'],avg_cov)\n",
    "    prob['Iris-virginica'] = P(x,mu['virginica'],avg_cov)\n",
    "    \n",
    "    return max(prob, key=prob.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Iris-versicolor'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LDA(trn_versicolor.iloc[0].as_matrix(),means,cov_avg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LDA: Evaluate on Training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training acc: 0.975\n"
     ]
    }
   ],
   "source": [
    "n_correct = 0\n",
    "for row in train.iterrows():\n",
    "    x = np.array(row[1][0:4])\n",
    "    y = row[1][4]\n",
    "    if LDA(x,means,cov_avg) == y:\n",
    "        n_correct += 1\n",
    "accuracy = n_correct/float(len(train))\n",
    "print 'Training acc:',accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LDA: Evaluate on Validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing acc: 1.0\n"
     ]
    }
   ],
   "source": [
    "n_correct = 0\n",
    "for row in test.iterrows():\n",
    "    x = np.array(row[1][0:4])\n",
    "    y = row[1][4]\n",
    "    if LDA(x,means,cov_avg) == y:\n",
    "        n_correct += 1\n",
    "accuracy = n_correct/float(len(test))\n",
    "print 'Testing acc:',accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quadratic Discriminant Analysis\n",
    "#### 3. Build a QDA classifier based on the training data. Report the training and test errors for your classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def QDA(x,means,covs):\n",
    "    prob = {}\n",
    "    prob['Iris-setosa'] = P(x,means['setosa'],covs['setosa'])\n",
    "    prob['Iris-versicolor'] = P(x,means['versicolor'],covs['versicolor'])\n",
    "    prob['Iris-virginica'] = P(x,means['virginica'],covs['virginica'])\n",
    "    \n",
    "    return max(prob, key=prob.get)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## QDA: Evaluate on Training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training acc: 0.983333333333\n"
     ]
    }
   ],
   "source": [
    "n_correct = 0\n",
    "for row in train.iterrows():\n",
    "    x = np.array(row[1][0:4])\n",
    "    y = row[1][4]\n",
    "    if QDA(x,means,covs) == y:\n",
    "        n_correct += 1\n",
    "accuracy = n_correct/float(len(train))\n",
    "print 'Training acc:',accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## QDA: Evaluate on Validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing acc: 1.0\n"
     ]
    }
   ],
   "source": [
    "n_correct = 0\n",
    "for row in test.iterrows():\n",
    "    x = np.array(row[1][0:4])\n",
    "    y = row[1][4]\n",
    "    y_hat = QDA(x,means,covs)\n",
    "    if y_hat == y:\n",
    "        n_correct += 1\n",
    "accuracy = n_correct/float(len(test))\n",
    "print 'Testing acc:',accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Seperability\n",
    "#### 4. Is there any class linearly separable from other classes? Explain your answer based on your experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iris-setosa accuracy: 1.0\n",
      "Iris-versicolor accuracy: 0.96\n",
      "Iris-virginica accuracy: 0.98\n"
     ]
    }
   ],
   "source": [
    "#do training & testing sets all at once, doesn't matter for this\n",
    "categories = ['Iris-setosa','Iris-versicolor','Iris-virginica']\n",
    "for category in categories:\n",
    "    X = table[table[4] == category]\n",
    "    n_correct = 0\n",
    "    for row in X.iterrows():\n",
    "        x = np.array(row[1][0:4])\n",
    "        y = row[1][4]\n",
    "        y_hat = LDA(x,means,cov_avg)\n",
    "        if y_hat == y:\n",
    "            n_correct += 1\n",
    "    accuracy = n_correct/float(len(X))\n",
    "    print category,'accuracy:',accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this result we may assume that the setosa class is linearly seperable, because this is the only class that our LDA classifier was able to perfectly classify."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature importance\n",
    "#### 5. Are any of the variables not important in classifying iris type? Explain your answer based on your experiments.\n",
    "drop each feature and do QDA & LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "LDA_accuracy = {}\n",
    "QDA_accuracy = {}\n",
    "\n",
    "for feature in range(trn_setosa.shape[1]):\n",
    "    #drop the chosen feature\n",
    "    setosa_ = trn_setosa.drop(feature,axis=1)\n",
    "    versicolor_ = trn_versicolor.drop(feature,axis=1)\n",
    "    virginica_ = trn_virginica.drop(feature,axis=1)\n",
    "    \n",
    "    test_ = test.drop(feature,axis=1)\n",
    "    \n",
    "    #train\n",
    "    means_ = {}\n",
    "    means_['setosa']  = my_mean(setosa_)\n",
    "    means_['versicolor'] = my_mean(versicolor_)\n",
    "    means_['virginica'] = my_mean(virginica_)\n",
    "\n",
    "    covs_ = {}\n",
    "    covs_['setosa'] = my_cov(setosa_)\n",
    "    covs_['versicolor'] = my_cov(versicolor_)\n",
    "    covs_['virginica'] = my_cov(virginica_)\n",
    "\n",
    "    cov_avg_ = (covs_['setosa'] + covs_['versicolor'] + covs_['virginica'])/3.0\n",
    "    \n",
    "    #LDA\n",
    "    n_correct = 0\n",
    "    for row in test_.iterrows():\n",
    "        x = np.array(row[1][0:3])\n",
    "        y = row[1][4]\n",
    "        if LDA(x,means_,cov_avg_) == y:\n",
    "            n_correct += 1\n",
    "    LDA_accuracy[feature]  = n_correct/float(len(test))\n",
    "    \n",
    "    #QDA  \n",
    "    n_correct = 0\n",
    "    for row in test_.iterrows():\n",
    "        x = np.array(row[1][0:3])\n",
    "        y = row[1][4]\n",
    "        if QDA(x,means_,covs_) == y:\n",
    "            n_correct += 1\n",
    "    QDA_accuracy[feature] = n_correct/float(len(test))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Format: {feature_removed: accuracy,...}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LDA: {0: 1.0, 1: 1.0, 2: 1.0, 3: 0.9666666666666667}\n",
      "QDA: {0: 1.0, 1: 1.0, 2: 1.0, 3: 0.9666666666666667}\n"
     ]
    }
   ],
   "source": [
    "print 'LDA:',LDA_accuracy\n",
    "print 'QDA:',QDA_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above result we can conclude that feature 3 (Petal width?) is perhaps more important, as only its removal had an impact on testing accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assuming Feature Independence\n",
    "#### 6. Assume the features are independent, i.e., âˆ‘ is a diagonal matrix. Repeat 2 and 3, and report your results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.13112179  0.          0.          0.        ]\n",
      " [ 0.          0.13271795  0.          0.        ]\n",
      " [ 0.          0.          0.02958333  0.        ]\n",
      " [ 0.          0.          0.          0.00994231]]\n",
      "[[ 0.27374359  0.          0.          0.        ]\n",
      " [ 0.          0.11087179  0.          0.        ]\n",
      " [ 0.          0.          0.20353205  0.        ]\n",
      " [ 0.          0.          0.          0.04307692]]\n",
      "[[ 0.46794231  0.          0.          0.        ]\n",
      " [ 0.          0.11323077  0.          0.        ]\n",
      " [ 0.          0.          0.34532692  0.        ]\n",
      " [ 0.          0.          0.          0.07425641]]\n"
     ]
    }
   ],
   "source": [
    "#convert cov matrices to diagonal (set non-diag entries to 0)\n",
    "indep_covs = {}\n",
    "for category,cov in covs.iteritems():\n",
    "    indep_covs[category] = zeros(cov.shape)\n",
    "    for row in range(cov.shape[0]):\n",
    "        for col in range(cov.shape[1]):\n",
    "            if row == col:\n",
    "                indep_covs[category][row][col] = cov[row][col]\n",
    "    print indep_covs[category]\n",
    "indep_cov_avg = (indep_covs['setosa']+indep_covs['virginica']+indep_covs['versicolor'])/3.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LDA: Evaluate on Training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training acc: 0.95\n"
     ]
    }
   ],
   "source": [
    "n_correct = 0\n",
    "for row in train.iterrows():\n",
    "    x = np.array(row[1][0:4])\n",
    "    y = row[1][4]\n",
    "    if LDA(x,means,indep_cov_avg) == y:\n",
    "        n_correct += 1\n",
    "accuracy = n_correct/float(len(train))\n",
    "print 'Training acc:',accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LDA: Evaluate on Validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing acc: 1.0\n"
     ]
    }
   ],
   "source": [
    "n_correct = 0\n",
    "for row in test.iterrows():\n",
    "    x = np.array(row[1][0:4])\n",
    "    y = row[1][4]\n",
    "    if LDA(x,means,indep_cov_avg) == y:\n",
    "        n_correct += 1\n",
    "accuracy = n_correct/float(len(test))\n",
    "print 'Testing acc:',accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## QDA: Evaluate on Training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training acc: 0.958333333333\n"
     ]
    }
   ],
   "source": [
    "n_correct = 0\n",
    "for row in train.iterrows():\n",
    "    x = np.array(row[1][0:4])\n",
    "    y = row[1][4]\n",
    "    if QDA(x,means,indep_covs) == y:\n",
    "        n_correct += 1\n",
    "accuracy = n_correct/float(len(train))\n",
    "print 'Training acc:',accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## QDA: Evaluate on Validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing acc: 1.0\n"
     ]
    }
   ],
   "source": [
    "n_correct = 0\n",
    "for row in test.iterrows():\n",
    "    x = np.array(row[1][0:4])\n",
    "    y = row[1][4]\n",
    "    y_hat = QDA(x,means,indep_covs)\n",
    "    if y_hat == y:\n",
    "        n_correct += 1\n",
    "accuracy = n_correct/float(len(test))\n",
    "print 'Testing acc:',accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While our testing acurracies remain perfect, training accuracies are lower than our QDA & LDA experiments without this assumption."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
